{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PAwTtXGKXfK6"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install tensorboard\n",
        "%pip install pytorch\n",
        "%pip install torchvision\n",
        "%pip install category_encoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tEnGU8bpXn6n"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils import data\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# sklearn classes\n",
        "from sklearn import metrics\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# sklearn utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Encoders\n",
        "from category_encoders import OrdinalEncoder, OneHotEncoder\n",
        "%load_ext tensorboard\n",
        "\n",
        "from torchvision import datasets, models, transforms\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import time\n",
        "import os\n",
        "import copy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vegobZrXYHof"
      },
      "source": [
        "# Preprocessing and augmenting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NxlsqcTfYBoW"
      },
      "outputs": [],
      "source": [
        "chan_num = 3\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToTensor(), \n",
        "    transforms.Grayscale(chan_num),\n",
        "    transforms.Normalize((0.5,), (0.3,))\n",
        "  ])\n",
        "test_transform = transforms.Compose([transforms.ToTensor(), transforms.Grayscale(chan_num), transforms.Normalize((0.5,), (0.3,))])\n",
        "val_transform = transforms.Compose([transforms.ToTensor(), transforms.Grayscale(chan_num), transforms.Normalize((0.5,), (0.3,)),])\n",
        "\n",
        "test_dataset = datasets.ImageFolder(root='triple_mnist/test', transform=train_transform)\n",
        "train_dataset = datasets.ImageFolder(root='triple_mnist/train', transform=train_transform)\n",
        "val_dataset = datasets.ImageFolder(root='triple_mnist/val', transform=val_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PHA7DccHYjHN"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vyx3rFlXYmuL"
      },
      "outputs": [],
      "source": [
        "dataloaders = {'train': train_loader, 'val': val_loader, 'test': test_loader}\n",
        "dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset), 'test': len(test_dataset)}\n",
        "image_datasets = {'train': train_dataset, 'val': val_dataset, 'test': test_dataset}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "CBIsaRyfYoz5",
        "outputId": "0ce2df13-fea4-41cf-c675-20cfa7d428e2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.5,])\n",
        "    std = np.array([0.3,])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "class_names = image_datasets['test'].classes\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders['test']))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs[0:8])\n",
        "\n",
        "imshow(out,title=[class_names[x] for x in classes][0:8])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhFYaZ4fYKHR"
      },
      "source": [
        "# Model itself"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "quPP1Ir9vBU5"
      },
      "outputs": [],
      "source": [
        "class MultiClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MultiClassifier, self).__init__()\n",
        "    self.ConvLayer1 = nn.Sequential(\n",
        "    nn.Conv2d(3, 84, 3), # 3, 256, 256\n",
        "    nn.MaxPool2d(2), # op: 16, 127, 127\n",
        "    nn.ReLU(), # op: 64, 127, 127\n",
        "    )\n",
        "    self.ConvLayer2 = nn.Sequential(\n",
        "    nn.Conv2d(84, 128, 3), # 64, 127, 127\n",
        "    nn.MaxPool2d(2), #op: 128, 63, 63\n",
        "    nn.ReLU() # op: 128, 63, 63\n",
        "    )\n",
        "    self.ConvLayer3 = nn.Sequential(\n",
        "    nn.Conv2d(128, 256, 3), # 128, 63, 63\n",
        "    nn.MaxPool2d(2), #op: 256, 30, 30\n",
        "    nn.ReLU() #op: 256, 30, 30\n",
        "    )\n",
        "    self.ConvLayer4 = nn.Sequential(\n",
        "    nn.Conv2d(256, 512, 3), # 256, 30, 30\n",
        "    nn.MaxPool2d(2), #op: 512, 3, 3\n",
        "    nn.ReLU(), #op: 512, 3, 3\n",
        "    nn.Dropout(0.2)\n",
        "    )\n",
        "    self.Linear1 = nn.Linear(512 * 3 * 3, 1024)\n",
        "    self.Linear2 = nn.Linear(1024, 256)\n",
        "    self.Linear3 = nn.Linear(256, 30)\n",
        "    self.act = nn.Sigmoid()\n",
        "  def forward(self, x):\n",
        "    x = self.ConvLayer1(x)\n",
        "    x = self.ConvLayer2(x)\n",
        "    x = self.ConvLayer3(x)\n",
        "    x = self.ConvLayer4(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.Linear1(x)\n",
        "    x = self.Linear2(x)\n",
        "    x = self.Linear3(x)\n",
        "    return self.act(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "z2HfGA-kqZcS"
      },
      "outputs": [],
      "source": [
        "def ml_split(num):\n",
        "  res = [0] * 30\n",
        "  res[int(num[0])] = 1\n",
        "  res[int(num[1]) + 10] = 1\n",
        "  res[int(num[2]) + 20] = 1\n",
        "  return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FGFZyn6d9g1F"
      },
      "outputs": [],
      "source": [
        "def hot_to_ind(tens):\n",
        "  _, preds = torch.max(tens[0].view(-1, 10), dim=1)\n",
        "  for i in range(1, len(tens)):\n",
        "    _, pred1 = torch.max(tens[i].view(-1, 10), dim=1)\n",
        "    preds = torch.cat((preds, pred1))\n",
        "  preds = preds.view(-1, 3)\n",
        "  return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xrpURXSHYL8W"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        print(f'Epoch {epoch}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_total_corrects = 0\n",
        "            running_any_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            num_steps = 0\n",
        "            print(len(dataloaders[phase]))\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                num_steps += 1\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    preds = hot_to_ind(outputs)\n",
        "                    target = torch.from_numpy(np.array([ml_split(image_datasets[phase].classes[label]) for label in labels])).to(device)\n",
        "                    target = target.type(torch.FloatTensor).to(device)\n",
        "                    loss = criterion(outputs, target)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                ind_target = hot_to_ind(target)\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_any_corrects += torch.sum(preds == ind_target)\n",
        "                for i in range(len(ind_target)):\n",
        "                  running_total_corrects += torch.equal(preds[i], ind_target[i])\n",
        "                  \n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_total_acc = float(running_total_corrects) / dataset_sizes[phase]\n",
        "            epoch_any_acc = running_any_corrects.double() / (3 * dataset_sizes[phase])\n",
        "\n",
        "            print(f'{phase} \\nLoss: {epoch_loss:.4f} Any Acc: {epoch_any_acc:.4f} Total Acc: {epoch_total_acc:.4f}')\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_total_acc > best_acc:\n",
        "                best_acc = epoch_total_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cU5yk8DWZrk-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32md:\\Work\\itoml.hw\\Assignment2\\A2_2.ipynb Ячейка 13\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/itoml.hw/Assignment2/A2_2.ipynb#X20sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/itoml.hw/Assignment2/A2_2.ipynb#X20sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m model_ft \u001b[39m=\u001b[39m MultiClassifier()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Work/itoml.hw/Assignment2/A2_2.ipynb#X20sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m model_ft \u001b[39m=\u001b[39m model_ft\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/itoml.hw/Assignment2/A2_2.ipynb#X20sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mBCELoss()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/itoml.hw/Assignment2/A2_2.ipynb#X20sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Observe that all parameters are being optimized\u001b[39;00m\n",
            "File \u001b[1;32md:\\Programs\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py:987\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    984\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m    985\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m--> 987\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
            "File \u001b[1;32md:\\Programs\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py:639\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    638\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 639\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    641\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    642\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    643\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    644\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    649\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    650\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "File \u001b[1;32md:\\Programs\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py:639\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    638\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 639\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    641\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    642\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    643\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    644\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    649\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    650\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "File \u001b[1;32md:\\Programs\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py:662\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    658\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    659\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    660\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    661\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 662\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    663\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    664\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
            "File \u001b[1;32md:\\Programs\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py:985\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    982\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[0;32m    983\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    984\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m--> 985\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "from torchvision import models\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "model_ft = MultiClassifier()\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.NAdam(model_ft.parameters(), lr=0.001, momentum_decay=0.5)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J0TXIAT2ZtUS",
        "outputId": "b930797a-5909-46df-9557-5bc72e96ac71"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32md:\\Work\\itoml.hw\\Assignment2\\A2_2.ipynb Ячейка 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Work/itoml.hw/Assignment2/A2_2.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_ft \u001b[39m=\u001b[39m train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Work/itoml.hw/Assignment2/A2_2.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model_ft\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mcnn97.pt\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[1;32md:\\Work\\itoml.hw\\Assignment2\\A2_2.ipynb Ячейка 14\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Work/itoml.hw/Assignment2/A2_2.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_model\u001b[39m(model, criterion, optimizer, scheduler, num_epochs\u001b[39m=\u001b[39m\u001b[39m25\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Work/itoml.hw/Assignment2/A2_2.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     since \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Work/itoml.hw/Assignment2/A2_2.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     best_model_wts \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39;49mdeepcopy(model\u001b[39m.\u001b[39;49mstate_dict())\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Work/itoml.hw/Assignment2/A2_2.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     best_acc \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Work/itoml.hw/Assignment2/A2_2.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, num_epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n",
            "File \u001b[1;32md:\\Programs\\Anaconda\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[0;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
            "File \u001b[1;32md:\\Programs\\Anaconda\\lib\\copy.py:296\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m dictiter:\n\u001b[0;32m    295\u001b[0m         key \u001b[39m=\u001b[39m deepcopy(key, memo)\n\u001b[1;32m--> 296\u001b[0m         value \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[0;32m    297\u001b[0m         y[key] \u001b[39m=\u001b[39m value\n\u001b[0;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[1;32md:\\Programs\\Anaconda\\lib\\copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    151\u001b[0m copier \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39m__deepcopy__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    152\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     y \u001b[39m=\u001b[39m copier(memo)\n\u001b[0;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     reductor \u001b[39m=\u001b[39m dispatch_table\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n",
            "File \u001b[1;32md:\\Programs\\Anaconda\\lib\\site-packages\\torch\\_tensor.py:134\u001b[0m, in \u001b[0;36mTensor.__deepcopy__\u001b[1;34m(self, memo)\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    126\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe default implementation of __deepcopy__() for wrapper subclasses \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    127\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39monly works for subclass types that implement clone() and for which \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mdifferent type.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    132\u001b[0m         )\n\u001b[0;32m    133\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 134\u001b[0m     new_storage \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage()\u001b[39m.\u001b[39;49m__deepcopy__(memo)\n\u001b[0;32m    135\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_quantized:\n\u001b[0;32m    136\u001b[0m         \u001b[39m# quantizer_params can be different type based on torch attribute\u001b[39;00m\n\u001b[0;32m    137\u001b[0m         quantizer_params: Union[\n\u001b[0;32m    138\u001b[0m             Tuple[torch\u001b[39m.\u001b[39mqscheme, \u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m],\n\u001b[0;32m    139\u001b[0m             Tuple[torch\u001b[39m.\u001b[39mqscheme, Tensor, Tensor, \u001b[39mint\u001b[39m],\n\u001b[0;32m    140\u001b[0m         ]\n",
            "File \u001b[1;32md:\\Programs\\Anaconda\\lib\\site-packages\\torch\\storage.py:597\u001b[0m, in \u001b[0;36mTypedStorage.__deepcopy__\u001b[1;34m(self, memo)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__deepcopy__\u001b[39m(\u001b[39mself\u001b[39m, memo):\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new_wrapped_storage(copy\u001b[39m.\u001b[39;49mdeepcopy(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_storage, memo))\n",
            "File \u001b[1;32md:\\Programs\\Anaconda\\lib\\copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    151\u001b[0m copier \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39m__deepcopy__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    152\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     y \u001b[39m=\u001b[39m copier(memo)\n\u001b[0;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     reductor \u001b[39m=\u001b[39m dispatch_table\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n",
            "File \u001b[1;32md:\\Programs\\Anaconda\\lib\\site-packages\\torch\\storage.py:97\u001b[0m, in \u001b[0;36m_StorageBase.__deepcopy__\u001b[1;34m(self, memo)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cdata \u001b[39min\u001b[39;00m memo:\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m memo[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cdata]\n\u001b[1;32m---> 97\u001b[0m new_storage \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclone()\n\u001b[0;32m     98\u001b[0m memo[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cdata] \u001b[39m=\u001b[39m new_storage\n\u001b[0;32m     99\u001b[0m \u001b[39mreturn\u001b[39;00m new_storage\n",
            "File \u001b[1;32md:\\Programs\\Anaconda\\lib\\site-packages\\torch\\storage.py:111\u001b[0m, in \u001b[0;36m_StorageBase.clone\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclone\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    110\u001b[0m     \u001b[39m\"\"\"Returns a copy of this storage\"\"\"\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39;49m(\u001b[39mself\u001b[39;49m)(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnbytes(), device\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\u001b[39m.\u001b[39mcopy_(\u001b[39mself\u001b[39m)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ],
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=5)\n",
        "model_ft.save('cnn97.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlWFUIgxZvXd"
      },
      "outputs": [],
      "source": [
        "def test_model(model):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_any_corrects = 0\n",
        "    running_total_corrects = 0\n",
        "\n",
        "    for inputs, labels in dataloaders['test']:\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      preds = hot_to_ind(outputs)\n",
        "      target = torch.from_numpy(np.array([ml_split(image_datasets['test'].classes[label]) for label in labels])).to(device)\n",
        "      target = target.type(torch.FloatTensor).to(device)\n",
        "\n",
        "      loss = F.binary_cross_entropy(outputs, target)\n",
        "\n",
        "      ind_target = hot_to_ind(target)\n",
        "\n",
        "      running_loss += loss.item() * inputs.size(0)\n",
        "      running_any_corrects += torch.sum(preds == ind_target)\n",
        "      for i in range(len(ind_target)):\n",
        "        running_total_corrects += torch.equal(preds[i], ind_target[i])\n",
        "\n",
        "    epoch_loss = running_loss / dataset_sizes['test']\n",
        "    epoch_total_acc = float(running_total_corrects) / dataset_sizes['test']\n",
        "    epoch_any_acc = running_any_corrects.double() / (3 * dataset_sizes['test'])\n",
        "\n",
        "    print(f'Test: \\nLoss: {epoch_loss} Any Acc: {epoch_any_acc:.4f} Total Acc: {epoch_total_acc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7uwTtVRpYoc",
        "outputId": "97ffffd9-a707-4c77-bff4-8925714a8104"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: \n",
            "Loss: 0.006679819885641336 Any Acc: 0.9922 Total Acc: 0.9766\n"
          ]
        }
      ],
      "source": [
        "test_model(model_ft)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtzVkKlKpa6M"
      },
      "outputs": [],
      "source": [
        "torch.save(model_ft.state_dict(), '/content/drive/MyDrive/MLA2/cnn97_02.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dhslec24xCA1"
      },
      "outputs": [],
      "source": [
        "model = torch.load('cnn97_active.pt', map_location=torch.device('cpu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "73ac9f730633c9c3aa54bc61d4a1518eb9b439b7d1460c455a4a24c056f5a2fe"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
